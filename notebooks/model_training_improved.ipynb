{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Breed Classification - Improved Training Pipeline\n",
    "\n",
    "This notebook implements a complete training pipeline with:\n",
    "- ✅ GlobalAveragePooling2D instead of Flatten\n",
    "- ✅ Fixed steps_per_epoch calculation\n",
    "- ✅ Two-stage training (Feature Extraction + Fine-tuning)\n",
    "- ✅ Comprehensive evaluation with confusion matrix\n",
    "- ✅ Learning curve visualization\n",
    "- ✅ Centralized configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup (uncomment if running on Colab)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/cat-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, GlobalAveragePooling2D, Dropout, Input\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, top_k_accuracy_score\n",
    ")\n",
    "\n",
    "# Import configuration\n",
    "sys.path.append('..')\n",
    "import config\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ GPU available: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠ GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"⚠ No GPU found. Training will run on CPU.\")\n",
    "\n",
    "# Enable mixed precision for faster training\n",
    "if config.MIXED_PRECISION:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    print(\"✓ Mixed precision enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Configuration and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "config.create_directories()\n",
    "\n",
    "# Print configuration\n",
    "config.print_config()\n",
    "\n",
    "# Get number of classes\n",
    "try:\n",
    "    NUM_CLASSES = config.get_num_classes()\n",
    "    print(f\"\\n✓ Found {NUM_CLASSES} cat breeds\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Cannot determine number of classes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Generators with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    **config.AUGMENTATION_CONFIG\n",
    ")\n",
    "\n",
    "# Validation and test data generators (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    str(config.TRAIN_DIR),\n",
    "    target_size=config.IMG_SIZE,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "validation_generator = val_test_datagen.flow_from_directory(\n",
    "    str(config.VAL_DIR),\n",
    "    target_size=config.IMG_SIZE,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    str(config.TEST_DIR),\n",
    "    target_size=config.IMG_SIZE,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Save class indices for later inference\n",
    "class_indices = train_generator.class_indices\n",
    "with open(config.MODELS_DIR / 'class_indices.json', 'w') as f:\n",
    "    json.dump(class_indices, f, indent=4)\n",
    "\n",
    "print(f\"\\n✓ Data generators created successfully\")\n",
    "print(f\"  Training samples: {train_generator.samples}\")\n",
    "print(f\"  Validation samples: {validation_generator.samples}\")\n",
    "print(f\"  Test samples: {test_generator.samples}\")\n",
    "print(f\"  Number of classes: {len(class_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model with GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, trainable=False):\n",
    "    \"\"\"\n",
    "    Build cat breed classification model using transfer learning\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of cat breeds to classify\n",
    "        trainable: Whether base model layers are trainable\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Load base model\n",
    "    base_model = ResNet50V2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(config.IMG_WIDTH, config.IMG_HEIGHT, config.IMG_CHANNELS)\n",
    "    )\n",
    "    \n",
    "    # Freeze/unfreeze base model\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    # Build model using Functional API\n",
    "    inputs = Input(shape=(config.IMG_WIDTH, config.IMG_HEIGHT, config.IMG_CHANNELS))\n",
    "    x = base_model(inputs, training=False)  # Important: set training=False for inference mode\n",
    "    \n",
    "    # Use GlobalAveragePooling2D instead of Flatten (much fewer parameters!)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Custom top layers\n",
    "    x = Dense(config.DENSE_UNITS, activation='relu')(x)\n",
    "    x = Dropout(config.DROPOUT_RATE)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)  # dtype for mixed precision\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build initial model (frozen base)\n",
    "model = build_model(NUM_CLASSES, trainable=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile Model - Stage 1 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model for Stage 1\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=config.LEARNING_RATE_STAGE1),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled for Stage 1 (Feature Extraction)\")\n",
    "print(f\"  Learning rate: {config.LEARNING_RATE_STAGE1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(stage=\"stage1\"):\n",
    "    \"\"\"\n",
    "    Create callbacks for training\n",
    "    \n",
    "    Args:\n",
    "        stage: Training stage name (for file naming)\n",
    "    \n",
    "    Returns:\n",
    "        List of Keras callbacks\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "    \n",
    "    # ModelCheckpoint\n",
    "    checkpoint_path = config.MODELS_DIR / f'cat_classifier_{stage}_best.keras'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=str(checkpoint_path),\n",
    "        monitor=config.CHECKPOINT_MONITOR,\n",
    "        mode=config.CHECKPOINT_MODE,\n",
    "        save_best_only=config.CHECKPOINT_SAVE_BEST_ONLY,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(checkpoint)\n",
    "    \n",
    "    # EarlyStopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=config.EARLY_STOPPING_MONITOR,\n",
    "        patience=config.EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=config.EARLY_STOPPING_RESTORE_BEST,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=config.REDUCE_LR_MONITOR,\n",
    "        factor=config.REDUCE_LR_FACTOR,\n",
    "        patience=config.REDUCE_LR_PATIENCE,\n",
    "        min_lr=config.REDUCE_LR_MIN_LR,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(reduce_lr)\n",
    "    \n",
    "    # TensorBoard\n",
    "    log_dir = config.LOGS_DIR / f\"{stage}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    tensorboard = TensorBoard(\n",
    "        log_dir=str(log_dir),\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    )\n",
    "    callbacks.append(tensorboard)\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "# Get callbacks for Stage 1\n",
    "callbacks_stage1 = get_callbacks(\"stage1\")\n",
    "print(\"✓ Callbacks configured for Stage 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Stage 1 - Feature Extraction (Fixed steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch correctly (use ceiling division)\n",
    "steps_per_epoch = int(np.ceil(train_generator.samples / config.BATCH_SIZE))\n",
    "validation_steps = int(np.ceil(validation_generator.samples / config.BATCH_SIZE))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 1: FEATURE EXTRACTION (Base Model Frozen)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "print(f\"Epochs: {config.EPOCHS_STAGE1}\")\n",
    "print(f\"Learning rate: {config.LEARNING_RATE_STAGE1}\")\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "# Train Stage 1\n",
    "history_stage1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=config.EPOCHS_STAGE1,\n",
    "    steps_per_epoch=steps_per_epoch,  # Fixed: use ceiling division\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_stage1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Stage 1 training completed!\")\n",
    "\n",
    "# Save history\n",
    "history_df_stage1 = pd.DataFrame(history_stage1.history)\n",
    "history_df_stage1.to_csv(config.OUTPUTS_DIR / 'training_history_stage1.csv', index=False)\n",
    "print(f\"✓ Training history saved to {config.OUTPUTS_DIR / 'training_history_stage1.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Stage 1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, stage=\"stage1\"):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    \n",
    "    Args:\n",
    "        history: Training history object or DataFrame\n",
    "        stage: Training stage name\n",
    "    \"\"\"\n",
    "    if hasattr(history, 'history'):\n",
    "        history = history.history\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Training Metrics - {stage.upper()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top-5 Accuracy\n",
    "    if 'top5_accuracy' in history:\n",
    "        axes[1, 0].plot(history['top5_accuracy'], label='Train Top-5 Acc', linewidth=2)\n",
    "        axes[1, 0].plot(history['val_top5_accuracy'], label='Val Top-5 Acc', linewidth=2)\n",
    "        axes[1, 0].set_title('Top-5 Accuracy', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Top-5 Accuracy')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate (if available)\n",
    "    if 'lr' in history:\n",
    "        axes[1, 1].plot(history['lr'], label='Learning Rate', linewidth=2, color='red')\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('LR')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.PLOTS_DIR / f'training_history_{stage}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Plot saved to {config.PLOTS_DIR / f'training_history_{stage}.png'}\")\n",
    "\n",
    "# Plot Stage 1 history\n",
    "plot_training_history(history_stage1, \"stage1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Stage 2 - Fine-tuning (Unfreeze top layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2: FINE-TUNING (Unfreezing top layers)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get the base model from our model\n",
    "base_model = model.layers[1]  # ResNet50V2 is the second layer\n",
    "\n",
    "# Unfreeze the top layers\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last N\n",
    "for layer in base_model.layers[:-config.UNFREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Base model has {len(base_model.layers)} layers\")\n",
    "print(f\"Unfreezing last {config.UNFREEZE_LAYERS} layers\")\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTrainable parameters: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=config.LEARNING_RATE_STAGE2),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model recompiled for fine-tuning\")\n",
    "print(f\"  Learning rate: {config.LEARNING_RATE_STAGE2} (10x lower than Stage 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get callbacks for Stage 2\n",
    "callbacks_stage2 = get_callbacks(\"stage2\")\n",
    "\n",
    "print(\"\\nStarting Stage 2 training...\\n\")\n",
    "\n",
    "# Train Stage 2\n",
    "history_stage2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=config.EPOCHS_STAGE2,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_stage2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Stage 2 training completed!\")\n",
    "\n",
    "# Save history\n",
    "history_df_stage2 = pd.DataFrame(history_stage2.history)\n",
    "history_df_stage2.to_csv(config.OUTPUTS_DIR / 'training_history_stage2.csv', index=False)\n",
    "print(f\"✓ Training history saved to {config.OUTPUTS_DIR / 'training_history_stage2.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Stage 2 history\n",
    "plot_training_history(history_stage2, \"stage2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Reset test generator\n",
    "test_generator.reset()\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "predictions = model.predict(test_generator, steps=int(np.ceil(test_generator.samples / config.BATCH_SIZE)), verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"\\n✓ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Top-5 accuracy\n",
    "top5_acc = top_k_accuracy_score(true_classes, predictions, k=5)\n",
    "print(f\"✓ Test Top-5 Accuracy: {top5_acc:.4f} ({top5_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "with open(config.REPORTS_DIR / 'classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print(f\"\\n✓ Classification report saved to {config.REPORTS_DIR / 'classification_report.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Number of Predictions'})\n",
    "plt.title('Confusion Matrix - Cat Breed Classification', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.PLOTS_DIR / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Confusion matrix saved to {config.PLOTS_DIR / 'confusion_matrix.png'}\")\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'Breed': class_names,\n",
    "    'Accuracy': per_class_accuracy,\n",
    "    'Correct': cm.diagonal(),\n",
    "    'Total': cm.sum(axis=1)\n",
    "})\n",
    "accuracy_df = accuracy_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Best Performing Breeds:\")\n",
    "print(accuracy_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 Worst Performing Breeds:\")\n",
    "print(accuracy_df.tail(10).to_string(index=False))\n",
    "\n",
    "# Save accuracy dataframe\n",
    "accuracy_df.to_csv(config.REPORTS_DIR / 'per_class_accuracy.csv', index=False)\n",
    "print(f\"\\n✓ Per-class accuracy saved to {config.REPORTS_DIR / 'per_class_accuracy.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model_path = config.MODELS_DIR / 'cat_breed_classifier_final.keras'\n",
    "model.save(str(final_model_path))\n",
    "print(f\"\\n✓ Final model saved to {final_model_path}\")\n",
    "\n",
    "# Save model summary\n",
    "with open(config.REPORTS_DIR / 'model_summary.txt', 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "print(f\"✓ Model summary saved to {config.REPORTS_DIR / 'model_summary.txt'}\")\n",
    "\n",
    "# Create training summary\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_architecture': config.BASE_MODEL_NAME,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'total_parameters': int(total_params),\n",
    "    'trainable_parameters': int(trainable_params),\n",
    "    'stage1': {\n",
    "        'epochs': len(history_stage1.history['loss']),\n",
    "        'best_val_accuracy': float(max(history_stage1.history['val_accuracy'])),\n",
    "        'best_val_loss': float(min(history_stage1.history['val_loss']))\n",
    "    },\n",
    "    'stage2': {\n",
    "        'epochs': len(history_stage2.history['loss']),\n",
    "        'best_val_accuracy': float(max(history_stage2.history['val_accuracy'])),\n",
    "        'best_val_loss': float(min(history_stage2.history['val_loss']))\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'accuracy': float(test_accuracy),\n",
    "        'top5_accuracy': float(top5_acc)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(config.REPORTS_DIR / 'training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "print(f\"✓ Training summary saved to {config.REPORTS_DIR / 'training_summary.json'}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(json.dumps(summary, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
